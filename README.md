# MLHackathon

# About India ML Hiring Hackathon 2019
This year, India will be celebrating its 73rd Independence Day !  For us proud Indians, this a day to celebrate our past, enjoy the present and be optimistic about our country's bright future.
 
What else could be the best way to do this but to help build career of future data scientists of India ! and that is exactly what we will be doing this Independence Day.
 
On this year's Independence, Analytics Vidhya is proud to present the "India Machine Learning Hiring Hackathon- 2019" - India's Largest Hiring Hackathon where every data science aspirant and professional will get an opportunity to showcase their talent and get the chance to interview with top organizations for job roles in Data Science, Machine Learning & Analytics. Be it Bengaluru, Delhi NCR, Mumbai, Pune, Chennai or Hyderabad; here is a chance to perform and get placed with a top company at your preferred location.
 
Data Science is already helping solve various kinds of problems in India and power projects like - Smart India, power the agriculture industry, define and deploy policies to uplift the social strength, improve the healthcare, electricity & water services and much more.  Get ready to solve an exciting data science challenge this Independence week and become a part of India's Next-gen Data Science Ecosystem- Jai Hind !
 
It's time to democratise data science and give more and more career opportunities to the data science community of India. 

# Approach 

# 1.Data Cleansing and Exploration
- Cleaning Data
- Found that Data was imbalanced. SO applied sampling techniues tog get balance data.
- Sampling tehniques used - undersampling, Random Over sampling , SMOTE .etc

# 2.Data Visualization
- Used Barplots to see distribution of features for each class
- Plot heatmap to find out mostly correlated features
- used Seaborn countplot to display count of each class for categorical features like finantial institution etc.

# 3.Feature Selection and Extraction
- Removed unwanted features like loan id
- based on heatmap remove highly correlated features
- Used PCA to extract top 10 components 
- Displayed each feature importance generated by random forest model
- Converted Cateorical features to numeric using One Hot Encoding

# 4.Building model
- Checked accuracy of different models like Random Forest, XGboost, LightGBM, Logistic regression, Naive Bays, KNN, Neural Network.
- Used Sklearn, Tensorlfow -GPU , keras, ensemle models libraries for model building

# 5.Validate Model
- Validated each model using F1_score, Recall, Precesion, Confusion matrics
- Model tends to overfitt data. Used Hypertunning parameters to reduce overfitting
- XGBoost (Boosting ensemble model) was working better with over sampling . Chose this as final predictive model.

# 6.Prediction
- Best prdictive model is used for submission. 

## Files And How to run it
### Predict_loan_deliquency.ipynb -  contains Data Visualization and overall approch 
Kindly go thourgh it before checking final submission. 
### Final_Submission_XGBOOST.ipyng - contains final submission 


### train.csv  - Training Data Set
### test.csv  - Test Data Set
